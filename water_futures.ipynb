{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water Futures approach to the Battle \n",
    "Spiegazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the workspace\n",
    "import eval\n",
    "from eval.evaluator import WaterFuturesEvaluator\n",
    "from eval.dashboard import run_dashboard\n",
    "\n",
    "# prepare the evaluator\n",
    "wfe = WaterFuturesEvaluator()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1\n",
    "Iteration one is where we try and test as many models with as many tuning as we can. Then, we will select only a handful of them and the best tuning for each family. \n",
    "Also we try which is the best reconciliation technique between those available.\n",
    "So the dataset is divided in *training* where we train and validate the models and the strategies and *test* where the models are tested on and the selected technique will produce the final forecast for the competition.\n",
    "Following iterations will have only the second part as the training part is not really necessary anymore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the evaluator for the next iteration\n",
    "wfe.next_iter()\n",
    "# Collect all the models and the settings that we are considering\n",
    "import models\n",
    "import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarks\n",
    "...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the models\n",
    "from models.benchmark import RollingAverageWeek, AutoRollingAverageWeek\n",
    "from preprocessing.impute_and_fill import FillZero, FillAvgWeek\n",
    "\n",
    "previous_week = {\n",
    "    'name': 'PrevWeek',\n",
    "    'model': RollingAverageWeek(1),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillZero()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "previous_week_v2 = {\n",
    "    'name': 'PrevWeek_v2',\n",
    "    'model': RollingAverageWeek(1),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillAvgWeek()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "average_week = {\n",
    "    'name': 'AvgWeek',\n",
    "    'model': RollingAverageWeek(None),\n",
    "    'preprocessing': {\n",
    "        'demand': [],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "rolling_average_2 = {\n",
    "    'name': 'RollingAverage_2',\n",
    "    'model': RollingAverageWeek(2),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillZero()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "rolling_average_4 = {\n",
    "    'name': 'RollingAverage_4',\n",
    "    'model': RollingAverageWeek(4),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillZero()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "rolling_average_8 = {\n",
    "    'name': 'RollingAverage_8',\n",
    "    'model': RollingAverageWeek(8),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillZero()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "auto_rollaw = {\n",
    "    'name': 'AutoRollingAverage',\n",
    "    'model': AutoRollingAverageWeek(),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillAvgWeek()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "\n",
    "models_configs = [\n",
    "    previous_week,\n",
    "    previous_week_v2,\n",
    "    average_week,\n",
    "    rolling_average_2,\n",
    "    rolling_average_4,\n",
    "    rolling_average_8,\n",
    "    auto_rollaw\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp Roll Ave \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.exp_rolling_average_week import ExpWeightedRollingWeek\n",
    "\n",
    "exp_rolling_average_2 = {\n",
    "    'name': 'ExpRollingAverage_2',\n",
    "    'model': ExpWeightedRollingWeek(2),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillAvgWeek()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "exp_rolling_average_4 = {\n",
    "    'name': 'ExpRollingAverage_4',\n",
    "    'model': ExpWeightedRollingWeek(4),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillAvgWeek()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "exp_rolling_average_8 = {\n",
    "    'name': 'ExpRollingAverage_8',\n",
    "    'model': ExpWeightedRollingWeek(8),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillAvgWeek()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "models_configs += [\n",
    "    exp_rolling_average_2,\n",
    "    exp_rolling_average_4,\n",
    "    exp_rolling_average_8\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern regression\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.pattern_regression import PatternRegression, PatternRegressionDaily\n",
    "from preprocessing.simple_transforms import Logarithm\n",
    "from preprocessing.weather_feature_engineering import RealFeel, DewPoint, WindChill\n",
    "\n",
    "pattern_regression = {\n",
    "    'name': f'PatternRegression',\n",
    "    'model': PatternRegression(),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm()],\n",
    "        'weather': [RealFeel(), DewPoint(), WindChill()]\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "pattern_regression_daily = {\n",
    "    'name': f'PatternRegressionDaily',\n",
    "    'model': PatternRegressionDaily(),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm()],\n",
    "        'weather': [RealFeel(), DewPoint(), WindChill()]\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "models_configs += [\n",
    "    pattern_regression,\n",
    "    pattern_regression_daily\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prophet\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Support for Torch based models not available. To enable them, install \"darts\", \"u8darts[torch]\" or \"u8darts[all]\" (with pip); or \"u8darts-torch\" or \"u8darts-all\" (with conda).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmodels_configs += [\\n    prophet\\n]\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.fbprophet import Fbprophet\n",
    "\n",
    "prophet = {\n",
    "    'name': 'FbProphet',\n",
    "    'model': Fbprophet(),\n",
    "    'preprocessing': {\n",
    "        'demand': [],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\"\"\"\n",
    "models_configs += [\n",
    "    prophet\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Models \n",
    "### LGBM\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.LGBM import LGBMrobust, LGBMsimple\n",
    "from preprocessing.advanced_transforms import LGBM_demand_features, LGBM_impute_nan_demand\n",
    "from preprocessing.advanced_transforms import LGBM_impute_nan_weather, LGBM_weather_features\n",
    "from preprocessing.advanced_transforms import  LGBM_prepare_test_dfs\n",
    "\n",
    "# No hyperparameter tuning for all parameters\n",
    "lgb_params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'num_leaves': 32,\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.01,\n",
    "        'feature_fraction': 0.6,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq':10,\n",
    "        'verbose': -1\n",
    "}\n",
    "\n",
    "lgbm_simple = {\n",
    "    'name': 'LGBMsimple',\n",
    "    'model': LGBMsimple(lgb_params = lgb_params),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm(), LGBM_impute_nan_demand(), LGBM_demand_features(no_last_week=1)],\n",
    "        'weather': [LGBM_impute_nan_weather(), LGBM_weather_features()],\n",
    "        'prepare_test_dfs': [LGBM_prepare_test_dfs()]\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "lgbm_robust = {\n",
    "    'name': 'LGBMrobust',\n",
    "    'model': LGBMrobust(lgb_params = lgb_params),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm(), LGBM_impute_nan_demand(), LGBM_demand_features(no_last_week=1)],\n",
    "        'weather': [LGBM_impute_nan_weather(), LGBM_weather_features()],\n",
    "        'prepare_test_dfs': [LGBM_prepare_test_dfs()]\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "lgbm_simple_with_last_week = {\n",
    "    'name': 'LGBMsimple_with_last week',\n",
    "    'model': LGBMsimple(lgb_params = lgb_params),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm(), LGBM_impute_nan_demand(), LGBM_demand_features(no_last_week=0)],\n",
    "        'weather': [LGBM_impute_nan_weather(), LGBM_weather_features()],\n",
    "        'prepare_test_dfs': [LGBM_prepare_test_dfs()]\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "\n",
    "models_configs += [\n",
    "    lgbm_simple,\n",
    "    lgbm_robust,\n",
    "    lgbm_simple_with_last_week\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.LGBM import XGBMsimple\n",
    "\n",
    "xgb_params = {\n",
    "    'colsample_bytree': 0.8,\n",
    "    'learning_rate': 0.02,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'objective':'reg:squarederror',\n",
    "    'min_child_weight':10,\n",
    "    'silent':1\n",
    "}\n",
    "\n",
    "xgbm_simple = {\n",
    "    'name': 'XGBMsimple',\n",
    "    'model': XGBMsimple(xgb_params = xgb_params),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm(), LGBM_impute_nan_demand(), LGBM_demand_features(no_last_week=0)],\n",
    "        'weather': [LGBM_impute_nan_weather(), LGBM_weather_features()],\n",
    "        'prepare_test_dfs': [LGBM_prepare_test_dfs()]\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "\n",
    "models_configs += [\n",
    "    xgbm_simple\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSMIX\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.TSMix import TSMix\n",
    "\n",
    "tsmix = {\n",
    "    'name': 'TSMix',\n",
    "    'model': TSMix(train_epochs=50, dropout=0.8),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm(), LGBM_impute_nan_demand()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "\n",
    "models_configs += [\n",
    "    tsmix\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavenet\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.wavenet import WaveNetModel, WaveNet_prepare_test_dfs, cfg\n",
    "\n",
    "wavenet = {\n",
    "    'name': 'WaveNet',\n",
    "    'model': WaveNetModel(cfg),\n",
    "    'preprocessing': {\n",
    "        'demand': [],\n",
    "        'weather': [],\n",
    "        'prepare_test_dfs': [WaveNet_prepare_test_dfs()]\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "\n",
    "models_configs += [\n",
    "    wavenet\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we can run the training of all these models and see how they perform\n",
    "wfe.curr_phase='train'\n",
    "wfe.n_train_seeds = 1\n",
    "for config in models_configs:\n",
    "    wfe.add_model(config)\n",
    "\n",
    "# See how they perform with the dashboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After studying the dashboard we selected the models that it made more sense to combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_models_sett = [auto_rollaw,\n",
    "                   pattern_regression]\n",
    "\"\"\",\n",
    "                   prophet,\n",
    "                   lgbm_simple,\n",
    "                   lgbm_robust,\n",
    "                   xgbm_simple,\n",
    "                   lgbm_simple_with_last_week,\n",
    "                   tsmix,\n",
    "                   wavenet]\"\"\"\n",
    "wfe.selected_models = [config['name'] for config in selected_models_sett]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase Ensembling study\n",
    "now let's see how the ensembling strategies perfrom on the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating strategy: naive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/48 [00:00<?, ?it/s]0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "ERROR:tornado.general:SEND Error: Host unreachable\n",
      "  0%|          | 0/48 [00:24<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m strategies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m      7\u001b[0m     naive\u001b[38;5;241m=\u001b[39mNaive()\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m strategy \u001b[38;5;129;01min\u001b[39;00m strategies:\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mwfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrategies\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/BoN2024/eval/evaluator.py:265\u001b[0m, in \u001b[0;36mWaterFuturesEvaluator.add_strategy\u001b[0;34m(self, name, strategy, force)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# Evaluate strategy\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvaluating strategy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 265\u001b[0m performance_indicators, forecast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresstrategies\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresstrategies[name] \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/repos/BoN2024/eval/evaluator.py:295\u001b[0m, in \u001b[0;36mWaterFuturesEvaluator.eval_strategy\u001b[0;34m(self, strategy)\u001b[0m\n\u001b[1;32m    292\u001b[0m ground_truth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdemand\u001b[38;5;241m.\u001b[39miloc[WEEK_LEN\u001b[38;5;241m*\u001b[39mtest_week_idx: WEEK_LEN\u001b[38;5;241m*\u001b[39m(test_week_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Load how the selected models perfromed for the test_weeks before this week\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m testresults \u001b[38;5;241m=\u001b[39m extract_results(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselected_models\u001b[49m\u001b[43m]\u001b[49m, \n\u001b[1;32m    296\u001b[0m                             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurr_it,\n\u001b[1;32m    297\u001b[0m                             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurr_phase,\n\u001b[1;32m    298\u001b[0m                             \u001b[38;5;28mrange\u001b[39m(test_week_idx\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_test_weeks, test_week_idx)\n\u001b[1;32m    299\u001b[0m                             )\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# Select the best model(s) for each DMA\u001b[39;00m\n\u001b[1;32m    302\u001b[0m best_models \u001b[38;5;241m=\u001b[39m strategy\u001b[38;5;241m.\u001b[39mfind_best_models(testresults)\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# Now let's see how the different strategies to reconcile the ensemble work\n",
    "from eval.strategies.best_on_history import BestOnTest\n",
    "\n",
    "\n",
    "strategies = {}\n",
    "strategies['best_on_test'] = BestOnTest()\n",
    "\n",
    "for strategy in strategies:\n",
    "    wfe.add_strategy(strategy, strategies[strategy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we look at the strategies in thesame dashboard and see how they perform\n",
    "\n",
    "# then we decide which one to go\n",
    "wfe.selected_strategy = BestOnTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the selected models on the test \n",
    "wfe.forecast_next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qui abbiamo il risultato finale da consegnare per la submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 2\n",
    "We get the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the new data\n",
    "\"\"\"\n",
    "wfe.next_iter()\n",
    "wfe.forecast_next()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BoN2024_dev_py3116",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
