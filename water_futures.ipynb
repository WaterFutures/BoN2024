{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water Futures approach to the Battle \n",
    "Spiegazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the workspace\n",
    "import eval\n",
    "from eval.evaluator import WaterFuturesEvaluator\n",
    "from eval.dashboard import run_dashboard\n",
    "\n",
    "# prepare the evaluator\n",
    "wfe = WaterFuturesEvaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1\n",
    "Iteration one is where we try and test as many models with as many tuning as we can. Then, we will select only a handful of them and the best tuning for each family. \n",
    "Also we try which is the best reconciliation technique between those available.\n",
    "So the dataset is divided in *training* where we train and validate the models and the strategies and *test* where the models are tested on and the selected technique will produce the final forecast for the competition.\n",
    "Following iterations will have only the second part as the training part is not really necessary anymore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the evaluator for the next iteration\n",
    "wfe.next_iter()\n",
    "# Collect all the models and the settings that we are considering\n",
    "import models\n",
    "import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarks\n",
    "...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the models\n",
    "from models.benchmark import RollingAverageWeek, AutoRollingAverageWeek\n",
    "from preprocessing.impute_and_fill import FillZero, FillAvgWeek\n",
    "\n",
    "previous_week = {\n",
    "    'name': 'PrevWeek',\n",
    "    'model': RollingAverageWeek(1),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillZero()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "previous_week_v2 = {\n",
    "    'name': 'PrevWeek_v2',\n",
    "    'model': RollingAverageWeek(1),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillAvgWeek()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "average_week = {\n",
    "    'name': 'AvgWeek',\n",
    "    'model': RollingAverageWeek(None),\n",
    "    'preprocessing': {\n",
    "        'demand': [],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "rolling_average_2 = {\n",
    "    'name': 'RollingAverage_2',\n",
    "    'model': RollingAverageWeek(2),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillZero()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "rolling_average_4 = {\n",
    "    'name': 'RollingAverage_4',\n",
    "    'model': RollingAverageWeek(4),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillZero()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "rolling_average_8 = {\n",
    "    'name': 'RollingAverage_8',\n",
    "    'model': RollingAverageWeek(8),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillZero()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "auto_rollaw = {\n",
    "    'name': 'AutoRollingAverage',\n",
    "    'model': AutoRollingAverageWeek(),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillAvgWeek()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "\n",
    "models_configs = [\n",
    "    previous_week,\n",
    "    previous_week_v2,\n",
    "    average_week,\n",
    "    rolling_average_2,\n",
    "    rolling_average_4,\n",
    "    rolling_average_8,\n",
    "    auto_rollaw\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp Roll Ave \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.exp_rolling_average_week import ExpWeightedRollingWeek\n",
    "\n",
    "exp_rolling_average_2 = {\n",
    "    'name': 'ExpRollingAverage_2',\n",
    "    'model': ExpWeightedRollingWeek(2),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillAvgWeek()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "exp_rolling_average_4 = {\n",
    "    'name': 'ExpRollingAverage_4',\n",
    "    'model': ExpWeightedRollingWeek(4),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillAvgWeek()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "exp_rolling_average_8 = {\n",
    "    'name': 'ExpRollingAverage_8',\n",
    "    'model': ExpWeightedRollingWeek(8),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillAvgWeek()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "models_configs += [\n",
    "    exp_rolling_average_2,\n",
    "    exp_rolling_average_4,\n",
    "    exp_rolling_average_8\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern regression\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.pattern_regression import PatternRegression, PatternRegressionDaily\n",
    "from preprocessing.simple_transforms import Logarithm\n",
    "from preprocessing.weather_feature_engineering import RealFeel, DewPoint, WindChill\n",
    "\n",
    "pattern_regression = {\n",
    "    'name': f'PatternRegression',\n",
    "    'model': PatternRegression(),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm()],\n",
    "        'weather': [RealFeel(), DewPoint(), WindChill()]\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "pattern_regression_daily = {\n",
    "    'name': f'PatternRegressionDaily',\n",
    "    'model': PatternRegressionDaily(),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm()],\n",
    "        'weather': [RealFeel(), DewPoint(), WindChill()]\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "models_configs += [\n",
    "    pattern_regression,\n",
    "    pattern_regression_daily\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prophet\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fbprophet import Fbprophet\n",
    "\n",
    "prophet = {\n",
    "    'name': 'FbProphet',\n",
    "    'model': Fbprophet(),\n",
    "    'preprocessing': {\n",
    "        'demand': [],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "models_configs += [\n",
    "    prophet\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Models \n",
    "### LGBM\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.LGBM import LGBMrobust, LGBMsimple\n",
    "from preprocessing.advanced_transforms import LGBM_demand_features, LGBM_impute_nan_demand\n",
    "from preprocessing.advanced_transforms import LGBM_impute_nan_weather, LGBM_weather_features\n",
    "from preprocessing.advanced_transforms import  LGBM_prepare_test_dfs\n",
    "\n",
    "# No hyperparameter tuning for all parameters\n",
    "lgb_params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'num_leaves': 32,\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.01,\n",
    "        'feature_fraction': 0.6,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq':10,\n",
    "        'verbose': -1\n",
    "}\n",
    "\n",
    "lgbm_simple = {\n",
    "    'name': 'LGBMsimple',\n",
    "    'model': LGBMsimple(lgb_params = lgb_params),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm(), LGBM_impute_nan_demand(), LGBM_demand_features(no_last_week=1)],\n",
    "        'weather': [LGBM_impute_nan_weather(), LGBM_weather_features()],\n",
    "        'prepare_test_dfs': [LGBM_prepare_test_dfs()]\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "lgbm_robust = {\n",
    "    'name': 'LGBMrobust',\n",
    "    'model': LGBMrobust(lgb_params = lgb_params),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm(), LGBM_impute_nan_demand(), LGBM_demand_features(no_last_week=1)],\n",
    "        'weather': [LGBM_impute_nan_weather(), LGBM_weather_features()],\n",
    "        'prepare_test_dfs': [LGBM_prepare_test_dfs()]\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "lgbm_simple_with_last_week = {\n",
    "    'name': 'LGBMsimple_with_last week',\n",
    "    'model': LGBMsimple(lgb_params = lgb_params),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm(), LGBM_impute_nan_demand(), LGBM_demand_features(no_last_week=0)],\n",
    "        'weather': [LGBM_impute_nan_weather(), LGBM_weather_features()],\n",
    "        'prepare_test_dfs': [LGBM_prepare_test_dfs()]\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "\n",
    "models_configs += [\n",
    "    lgbm_simple,\n",
    "    lgbm_robust,\n",
    "    lgbm_simple_with_last_week\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.LGBM import XGBMsimple\n",
    "\n",
    "xgb_params = {\n",
    "    'colsample_bytree': 0.8,\n",
    "    'learning_rate': 0.02,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'objective':'reg:squarederror',\n",
    "    'min_child_weight':10,\n",
    "    'silent':1\n",
    "}\n",
    "\n",
    "xgbm_simple = {\n",
    "    'name': 'XGBMsimple',\n",
    "    'model': XGBMsimple(xgb_params = xgb_params),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm(), LGBM_impute_nan_demand(), LGBM_demand_features(no_last_week=0)],\n",
    "        'weather': [LGBM_impute_nan_weather(), LGBM_weather_features()],\n",
    "        'prepare_test_dfs': [LGBM_prepare_test_dfs()]\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "\n",
    "models_configs += [\n",
    "    xgbm_simple\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSMIX\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.TSMix import TSMix\n",
    "\n",
    "tsmix = {\n",
    "    'name': 'TSMix',\n",
    "    'model': TSMix(train_epochs=50, dropout=0.8),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm(), LGBM_impute_nan_demand()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "\n",
    "models_configs += [\n",
    "    tsmix\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavenet\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.wavenet import WaveNetModel, WaveNet_prepare_test_dfs, cfg\n",
    "\n",
    "wavenet = {\n",
    "    'name': 'WaveNet',\n",
    "    'model': WaveNetModel(cfg),\n",
    "    'preprocessing': {\n",
    "        'demand': [],\n",
    "        'weather': [],\n",
    "        'prepare_test_dfs': [WaveNet_prepare_test_dfs()]\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "\n",
    "models_configs += [\n",
    "    wavenet\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating PrevWeek with seed 0 in train phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:00<00:00, 460.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating PrevWeek_v2 with seed 0 in train phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:00<00:00, 448.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating AvgWeek with seed 0 in train phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:00<00:00, 701.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RollingAverage_2 with seed 0 in train phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:00<00:00, 723.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RollingAverage_4 with seed 0 in train phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:00<00:00, 523.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RollingAverage_8 with seed 0 in train phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:00<00:00, 759.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating AutoRollingAverage with seed 0 in train phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:04<00:00, 12.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating AutoRollingAverage with seed 1 in train phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:04<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating AutoRollingAverage with seed 2 in train phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:04<00:00, 11.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating AutoRollingAverage with seed 3 in train phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:04<00:00, 11.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating AutoRollingAverage with seed 4 in train phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:04<00:00, 11.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# Now, we can run the training of all these models and see how they perform\n",
    "wfe.curr_phase='train'\n",
    "\n",
    "for config in models_configs:\n",
    "    wfe.add_model(config)\n",
    "\n",
    "# See how they perform with the dashboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After studying the dashboard we selected the models that it made more sense to combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_models_sett = [auto_rollaw,\n",
    "                   pattern_regression,\n",
    "                   prophet,\n",
    "                   lgbm_simple,\n",
    "                   lgbm_robust,\n",
    "                   xgbm_simple,\n",
    "                   lgbm_simple_with_last_week,\n",
    "                   tsmix,\n",
    "                   wavenet]\n",
    "wfe.selected_models( [config['name'] for config in selected_models_sett] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase Ensembling study\n",
    "now let's see how the ensembling strategies perfrom on the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Now let's see how the different strategies to reconcile the ensemble work\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mwfe\u001b[49m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/pyenvs/BoN2024_dev_py3116/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/pyenvs/BoN2024_dev_py3116/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Now let's see how the different strategies to reconcile the ensemble work\n",
    "from eval.strategies.naive import Naive\n",
    "#from eval.strategies import BestOnLastW, BestOnLastNW, BestOnLastNW_weighted\n",
    "#from eval.strategies import BestXWeightedSum\n",
    "\n",
    "strategies = dict(\n",
    "    naive=Naive()\n",
    ")\n",
    "\n",
    "for strategy in strategies:\n",
    "    wfe.add_strategy(strategy, strategies[strategy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we look at the strategies in thesame dashboard and see how they perform\n",
    "\n",
    "# then we decide which one to go\n",
    "wfe.selected_strategy = 'naive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the selected models on the test \n",
    "wfe.forecast_next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qui abbiamo il risultato finale da consegnare per la submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 2\n",
    "We get the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the new data\n",
    "\"\"\"\n",
    "wfe.next_iter()\n",
    "wfe.forecast_next()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BoN2024_dev_py3116",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
