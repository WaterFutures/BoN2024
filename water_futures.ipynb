{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water Futures approach to the Battle \n",
    "Spiegazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the workspace\n",
    "import eval\n",
    "from eval.evaluator import WaterFuturesEvaluator\n",
    "from eval.dashboard import run_dashboard\n",
    "\n",
    "# prepare the evaluator\n",
    "wfe = WaterFuturesEvaluator()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1\n",
    "Iteration one is where we try and test as many models with as many tuning as we can. Then, we will select only a handful of them and the best tuning for each family. \n",
    "Also we try which is the best reconciliation technique between those available.\n",
    "So the dataset is divided in *training* where we train and validate the models and the strategies and *test* where the models are tested on and the selected technique will produce the final forecast for the competition.\n",
    "Following iterations will have only the second part as the training part is not really necessary anymore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the evaluator for the next iteration\n",
    "wfe.next_iter()\n",
    "# Collect all the models and the settings that we are considering\n",
    "import models\n",
    "import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarks\n",
    "...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the models\n",
    "from models.benchmark import RollingAverageWeek, AutoRollingAverageWeek\n",
    "from preprocessing.impute_and_fill import FillZero, FillAvgWeek\n",
    "\n",
    "previous_week = {\n",
    "    'name': 'PrevWeek',\n",
    "    'model': RollingAverageWeek(1),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillZero()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "previous_week_v2 = {\n",
    "    'name': 'PrevWeek_v2',\n",
    "    'model': RollingAverageWeek(1),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillAvgWeek()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "average_week = {\n",
    "    'name': 'AvgWeek',\n",
    "    'model': RollingAverageWeek(None),\n",
    "    'preprocessing': {\n",
    "        'demand': [],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "rolling_average_2 = {\n",
    "    'name': 'RollingAverage_2',\n",
    "    'model': RollingAverageWeek(2),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillZero()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "rolling_average_4 = {\n",
    "    'name': 'RollingAverage_4',\n",
    "    'model': RollingAverageWeek(4),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillZero()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "rolling_average_8 = {\n",
    "    'name': 'RollingAverage_8',\n",
    "    'model': RollingAverageWeek(8),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillZero()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "auto_rollaw = {\n",
    "    'name': 'AutoRollingAverage',\n",
    "    'model': AutoRollingAverageWeek(),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillAvgWeek()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "\n",
    "models_configs = [\n",
    "    previous_week,\n",
    "    previous_week_v2,\n",
    "    average_week,\n",
    "    rolling_average_2,\n",
    "    rolling_average_4,\n",
    "    rolling_average_8,\n",
    "    auto_rollaw\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp Roll Ave \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.exp_rolling_average_week import ExpWeightedRollingWeek\n",
    "\n",
    "exp_rolling_average_2 = {\n",
    "    'name': 'ExpRollingAverage_2',\n",
    "    'model': ExpWeightedRollingWeek(2),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillAvgWeek()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "exp_rolling_average_4 = {\n",
    "    'name': 'ExpRollingAverage_4',\n",
    "    'model': ExpWeightedRollingWeek(4),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillAvgWeek()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "exp_rolling_average_8 = {\n",
    "    'name': 'ExpRollingAverage_8',\n",
    "    'model': ExpWeightedRollingWeek(8),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillAvgWeek()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "models_configs += [\n",
    "    exp_rolling_average_2,\n",
    "    exp_rolling_average_4,\n",
    "    exp_rolling_average_8\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern regression\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.pattern_regression import PatternRegression, PatternRegressionDaily\n",
    "from preprocessing.simple_transforms import Logarithm\n",
    "from preprocessing.weather_feature_engineering import RealFeel, DewPoint, WindChill\n",
    "\n",
    "pattern_regression = {\n",
    "    'name': f'PatternRegression',\n",
    "    'model': PatternRegression(),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm()],\n",
    "        'weather': [RealFeel(), DewPoint(), WindChill()]\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "pattern_regression_daily = {\n",
    "    'name': f'PatternRegressionDaily',\n",
    "    'model': PatternRegressionDaily(),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm()],\n",
    "        'weather': [RealFeel(), DewPoint(), WindChill()]\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "models_configs += [\n",
    "    pattern_regression,\n",
    "    pattern_regression_daily\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prophet\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Support for Torch based models not available. To enable them, install \"darts\", \"u8darts[torch]\" or \"u8darts[all]\" (with pip); or \"u8darts-torch\" or \"u8darts-all\" (with conda).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmodels_configs += [\\n    prophet\\n]\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.fbprophet import Fbprophet\n",
    "\n",
    "prophet = {\n",
    "    'name': 'FbProphet',\n",
    "    'model': Fbprophet(),\n",
    "    'preprocessing': {\n",
    "        'demand': [],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\"\"\"\n",
    "models_configs += [\n",
    "    prophet\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Models \n",
    "### LGBM\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.LGBM import LGBMrobust, LGBMsimple\n",
    "from preprocessing.advanced_transforms import LGBM_demand_features, LGBM_impute_nan_demand\n",
    "from preprocessing.advanced_transforms import LGBM_impute_nan_weather, LGBM_weather_features\n",
    "from preprocessing.advanced_transforms import  LGBM_prepare_test_dfs\n",
    "\n",
    "# No hyperparameter tuning for all parameters\n",
    "lgb_params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'num_leaves': 32,\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.01,\n",
    "        'feature_fraction': 0.6,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq':10,\n",
    "        'verbose': -1\n",
    "}\n",
    "\n",
    "lgbm_simple = {\n",
    "    'name': 'LGBMsimple',\n",
    "    'model': LGBMsimple(lgb_params = lgb_params),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm(), LGBM_impute_nan_demand(), LGBM_demand_features(no_last_week=1)],\n",
    "        'weather': [LGBM_impute_nan_weather(), LGBM_weather_features()],\n",
    "        'prepare_test_dfs': [LGBM_prepare_test_dfs()]\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "lgbm_robust = {\n",
    "    'name': 'LGBMrobust',\n",
    "    'model': LGBMrobust(lgb_params = lgb_params),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm(), LGBM_impute_nan_demand(), LGBM_demand_features(no_last_week=1)],\n",
    "        'weather': [LGBM_impute_nan_weather(), LGBM_weather_features()],\n",
    "        'prepare_test_dfs': [LGBM_prepare_test_dfs()]\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "lgbm_simple_with_last_week = {\n",
    "    'name': 'LGBMsimple_with_last week',\n",
    "    'model': LGBMsimple(lgb_params = lgb_params),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm(), LGBM_impute_nan_demand(), LGBM_demand_features(no_last_week=0)],\n",
    "        'weather': [LGBM_impute_nan_weather(), LGBM_weather_features()],\n",
    "        'prepare_test_dfs': [LGBM_prepare_test_dfs()]\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "\n",
    "models_configs += [\n",
    "    lgbm_simple,\n",
    "    lgbm_robust,\n",
    "    lgbm_simple_with_last_week\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.LGBM import XGBMsimple\n",
    "\n",
    "xgb_params = {\n",
    "    'colsample_bytree': 0.8,\n",
    "    'learning_rate': 0.02,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'objective':'reg:squarederror',\n",
    "    'min_child_weight':10,\n",
    "    'silent':1\n",
    "}\n",
    "\n",
    "xgbm_simple = {\n",
    "    'name': 'XGBMsimple',\n",
    "    'model': XGBMsimple(xgb_params = xgb_params),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm(), LGBM_impute_nan_demand(), LGBM_demand_features(no_last_week=0)],\n",
    "        'weather': [LGBM_impute_nan_weather(), LGBM_weather_features()],\n",
    "        'prepare_test_dfs': [LGBM_prepare_test_dfs()]\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "\n",
    "models_configs += [\n",
    "    xgbm_simple\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSMIX\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.TSMix import TSMix\n",
    "\n",
    "tsmix = {\n",
    "    'name': 'TSMix',\n",
    "    'model': TSMix(train_epochs=50, dropout=0.8),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm(), LGBM_impute_nan_demand()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "\n",
    "models_configs += [\n",
    "    tsmix\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavenet\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.wavenet import WaveNetModel, WaveNet_prepare_test_dfs, cfg\n",
    "\n",
    "#cfg['device'] = 'cuda' # if you have a compatible NVIDIA GPU\n",
    "cfg['device'] = 'mps:0' # if you have Metal acceleration on your Mac (https://developer.apple.com/metal/pytorch/)\n",
    "#cfg['device'] = 'cpu' # for every other machine without GPU acceleration\n",
    "\n",
    "wavenet = {\n",
    "    'name': 'WaveNet',\n",
    "    'model': WaveNetModel(cfg),\n",
    "    'preprocessing': {\n",
    "        'demand': [],\n",
    "        'weather': [],\n",
    "        'prepare_test_dfs': [WaveNet_prepare_test_dfs()]\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "\n",
    "models_configs += [\n",
    "    wavenet\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we can run the training of all these models and see how they perform\n",
    "wfe.curr_phase='train'\n",
    "wfe.n_train_seeds = 1\n",
    "for config in models_configs:\n",
    "    wfe.add_model(config)\n",
    "\n",
    "# See how they perform with the dashboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After studying the dashboard we selected the models that it made more sense to combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_models_sett = [auto_rollaw,\n",
    "                   pattern_regression,\n",
    "                   lgbm_simple,\n",
    "                   lgbm_robust,\n",
    "                   xgbm_simple,\n",
    "                   lgbm_simple_with_last_week,\n",
    "                   wavenet\n",
    "                   ]\n",
    "wfe.selected_models = [config['name'] for config in selected_models_sett]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase Ensembling study\n",
    "now let's see how the ensembling strategies perfrom on the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's see how the different strategies to reconcile the ensemble work\n",
    "from eval.strategies.best_on_history import BestOnLastNW, BestOnTest\n",
    "\n",
    "strategies = {}\n",
    "strategies['best_on_last'] = BestOnLastNW(1)\n",
    "strategies['best_on_last_2'] = BestOnLastNW(2)\n",
    "strategies['best_on_last_3'] = BestOnLastNW(3)\n",
    "strategies['best_on_test'] = BestOnTest() # like bestonlastNw(4)\n",
    "\n",
    "from eval.strategies.weighted_averages import WeightedAverage\n",
    "import numpy as np\n",
    "\n",
    "top5 = [lgbm_robust, lgbm_simple, xgbm_simple, lgbm_simple_with_last_week, wavenet]\n",
    "\n",
    "strategies['avg_top5'] = WeightedAverage([config['name'] for config in top5], np.ones(len(top5))/len(top5))\n",
    "\n",
    "top3 = [lgbm_robust, lgbm_simple, wavenet]\n",
    "strategies['avg_top3'] = WeightedAverage([config['name'] for config in top3], \n",
    "                                         np.ones(len(top3))/len(top3))\n",
    "\n",
    "strategies['lgbm_wavenet'] = WeightedAverage([lgbm_robust['name'], wavenet['name']], \n",
    "                                             np.array([0.5, 0.5]))\n",
    "\n",
    "# As suggested by Pansos, all the gbm models should count as one model, so 1/3 to rollaverage, 1/3 to gbms 1/3 to wavenet,\n",
    "# and then 1/4 to each of the gbms \n",
    "strategies['gbms_wavenet_arw'] = WeightedAverage([config['name'] for config in selected_models_sett],\n",
    "                                                  np.array([1/3, 0, 1/3/4, 1/3/4, 1/3/4, 1/3/4, 1/3]))\n",
    "\n",
    "# Last strategy is the weighted average where the weights are the ratio between mean and std on the training dataset\n",
    "from Utils.process_results import extract_from\n",
    "from eval.data_loading_helpers import DMAS_NAMES\n",
    "\n",
    "weights = {}\n",
    "for dma in DMAS_NAMES:\n",
    "    dma_pis = [extract_from(wfe.results[model], 1, 'train', 'performance_indicators') for model in wfe.selected_models]\n",
    "    dmas_pi_weight = np.array([(\n",
    "            dma_pis[i].groupby('DMA').mean().loc[dma,'PI3']\n",
    "                                )/(\n",
    "            dma_pis[i].groupby('DMA').std().loc[dma,'PI3']\n",
    "                                ) for i in range(len(dma_pis)) ])\n",
    "    dmas_pi_weight[1] = 0 # I don't want to consider the pattern regression\n",
    "    weights[dma] = dmas_pi_weight/dmas_pi_weight.sum()\n",
    "\n",
    "strategies['wavg_train'] = WeightedAverage([model for model in wfe.selected_models], \n",
    "                                           weights)\n",
    "\n",
    "for strategy in strategies:\n",
    "    wfe.add_strategy(strategy, strategies[strategy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we look at the strategies in thesame dashboard and see how they perform\n",
    "\n",
    "# then we decide which one to go\n",
    "wfe.selected_strategy = 'avg_top5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating AutoRollingAverage with seed 0 in test phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating AutoRollingAverage with seed 1 in test phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 10.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating AutoRollingAverage with seed 2 in test phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 10.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating AutoRollingAverage with seed 3 in test phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 10.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating AutoRollingAverage with seed 4 in test phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 10.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating AutoRollingAverage with seed 5 in test phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  9.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating AutoRollingAverage with seed 6 in test phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 11.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating AutoRollingAverage with seed 7 in test phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating AutoRollingAverage with seed 8 in test phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  9.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating AutoRollingAverage with seed 9 in test phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  9.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating PatternRegression with seed 0 in test phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LGBMsimple with seed 0 in test phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [04:28<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# run the selected models on the test \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mwfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforecast_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/BoN2024/eval/evaluator.py:357\u001b[0m, in \u001b[0;36mWaterFuturesEvaluator.forecast_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurr_phase \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_models:\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfigs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# add model will send the correct database to the eval model function\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m# etract the results of the selected models accordingly\u001b[39;00m\n\u001b[1;32m    360\u001b[0m testresults \u001b[38;5;241m=\u001b[39m extract_results({k: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_models \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults}, \n\u001b[1;32m    361\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurr_it,\n\u001b[1;32m    362\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurr_phase,\n\u001b[1;32m    363\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_weeks\n\u001b[1;32m    364\u001b[0m                             )\n",
      "File \u001b[0;32m~/repos/BoN2024/eval/evaluator.py:161\u001b[0m, in \u001b[0;36mWaterFuturesEvaluator.add_model\u001b[0;34m(self, config, force)\u001b[0m\n\u001b[1;32m    159\u001b[0m l__seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(seed)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with seed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurr_phase\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m phase\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 161\u001b[0m performance_indicators, forecast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweek_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults[config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/repos/BoN2024/eval/evaluator.py:222\u001b[0m, in \u001b[0;36mWaterFuturesEvaluator.eval_model\u001b[0;34m(self, config, test_week_idcs, seed)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprepare_test_dfs\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessing\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m preprocessing_step \u001b[38;5;129;01min\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessing\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdemand\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m--> 222\u001b[0m         demand_test \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessing_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdemand_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m preprocessing_step \u001b[38;5;129;01min\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessing\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweather\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    225\u001b[0m         weather_test \u001b[38;5;241m=\u001b[39m preprocessing_step\u001b[38;5;241m.\u001b[39mtransform(weather_test)\n",
      "File \u001b[0;32m~/repos/BoN2024/preprocessing/advanced_transforms.py:142\u001b[0m, in \u001b[0;36mLGBM_demand_features.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Exponential smoothing of the series. This feature together with the next 2, try to capture the standard patterns\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# of the series in different ways. It only uses data from the previous week. This is because the only seasonality within a week is a 24 hour\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# seasonality, whereas over longer horizons, things get less obvious\u001b[39;00m\n\u001b[1;32m    141\u001b[0m model \u001b[38;5;241m=\u001b[39m ExponentialSmoothing(X_w\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39mWEEK_LEN:]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m), trend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmul\u001b[39m\u001b[38;5;124m\"\u001b[39m, seasonal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmul\u001b[39m\u001b[38;5;124m\"\u001b[39m, seasonal_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m)\n\u001b[0;32m--> 142\u001b[0m fit \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m pred \u001b[38;5;241m=\u001b[39m fit\u001b[38;5;241m.\u001b[39mforecast(WEEK_LEN)\n\u001b[1;32m    144\u001b[0m X\u001b[38;5;241m.\u001b[39mloc[X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_week\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m w, dma\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_smooth_lagged\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m~/pyenvs/BoN2024_dev_py3116/lib/python3.11/site-packages/pandas/util/_decorators.py:213\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m    212\u001b[0m     kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pyenvs/BoN2024_dev_py3116/lib/python3.11/site-packages/pandas/util/_decorators.py:213\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m    212\u001b[0m     kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pyenvs/BoN2024_dev_py3116/lib/python3.11/site-packages/pandas/util/_decorators.py:213\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m    212\u001b[0m     kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pyenvs/BoN2024_dev_py3116/lib/python3.11/site-packages/statsmodels/tsa/holtwinters/model.py:1143\u001b[0m, in \u001b[0;36mExponentialSmoothing.fit\u001b[0;34m(self, smoothing_level, smoothing_trend, smoothing_seasonal, damping_trend, optimized, remove_bias, start_params, method, minimize_kwargs, use_brute, use_boxcox, use_basinhopping, initial_level, initial_trend)\u001b[0m\n\u001b[1;32m   1141\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSLSQP\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m method\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimized:\n\u001b[0;32m-> 1143\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimize_parameters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_brute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminimize_kwargs\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1147\u001b[0m     l0, b0, s0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_values(\n\u001b[1;32m   1148\u001b[0m         initial_level\u001b[38;5;241m=\u001b[39minitial_level, initial_trend\u001b[38;5;241m=\u001b[39minitial_trend\n\u001b[1;32m   1149\u001b[0m     )\n",
      "File \u001b[0;32m~/pyenvs/BoN2024_dev_py3116/lib/python3.11/site-packages/statsmodels/tsa/holtwinters/model.py:839\u001b[0m, in \u001b[0;36mExponentialSmoothing._optimize_parameters\u001b[0;34m(self, data, use_brute, method, kwargs)\u001b[0m\n\u001b[1;32m    835\u001b[0m bounds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(orig_bounds[:\u001b[38;5;241m3\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m    836\u001b[0m hw_args \u001b[38;5;241m=\u001b[39m HoltWintersArgs(\n\u001b[1;32m    837\u001b[0m     sel\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m), params, bounds, y, m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnobs\n\u001b[1;32m    838\u001b[0m )\n\u001b[0;32m--> 839\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_starting_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_brute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43msel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhw_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_alpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;66;03m# We always use [0, 1] for a, b and g and handle transform inside\u001b[39;00m\n\u001b[1;32m    851\u001b[0m mod_bounds \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m+\u001b[39m orig_bounds[\u001b[38;5;241m3\u001b[39m:]\n",
      "File \u001b[0;32m~/pyenvs/BoN2024_dev_py3116/lib/python3.11/site-packages/statsmodels/tsa/holtwinters/model.py:747\u001b[0m, in \u001b[0;36mExponentialSmoothing._get_starting_values\u001b[0;34m(self, params, start_params, use_brute, sel, hw_args, bounds, alpha, func)\u001b[0m\n\u001b[1;32m    745\u001b[0m best_params \u001b[38;5;241m=\u001b[39m points[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m point \u001b[38;5;129;01min\u001b[39;00m points:\n\u001b[0;32m--> 747\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[43mopt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhw_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;241m<\u001b[39m best_val:\n\u001b[1;32m    749\u001b[0m         best_params \u001b[38;5;241m=\u001b[39m point\n",
      "File \u001b[0;32m~/pyenvs/BoN2024_dev_py3116/lib/python3.11/site-packages/statsmodels/tsa/holtwinters/model.py:81\u001b[0m, in \u001b[0;36mopt_wrapper.<locals>.f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 81\u001b[0m     err \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m err\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m err\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run the selected models on the test \n",
    "wfe.n_test_seeds = 3\n",
    "wfe.forecast_next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qui abbiamo il risultato finale da consegnare per la submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 2\n",
    "We get the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the new data\n",
    "\"\"\"\n",
    "wfe.next_iter()\n",
    "wfe.forecast_next()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BoN2024_dev_py3116",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
