{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water Futures approach to the Battle \n",
    "Spiegazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the workspace\n",
    "import eval\n",
    "from eval.evaluator import WaterFuturesEvaluator\n",
    "from eval.dashboard import run_dashboard\n",
    "\n",
    "# prepare the evaluator\n",
    "wfe = WaterFuturesEvaluator()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1\n",
    "Iteration one is where we try and test as many models with as many tuning as we can. Then, we will select only a handful of them and the best tuning for each family. \n",
    "Also we try which is the best reconciliation technique between those available.\n",
    "So the dataset is divided in *training* where we train and validate the models and the strategies and *test* where the models are tested on and the selected technique will produce the final forecast for the competition.\n",
    "Following iterations will have only the second part as the training part is not really necessary anymore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the evaluator for the next iteration\n",
    "wfe.next_iter()\n",
    "# Collect all the models and the settings that we are considering\n",
    "import models\n",
    "import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarks\n",
    "...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the models\n",
    "from models.benchmark import RollingAverageWeek, AutoRollingAverageWeek\n",
    "from preprocessing.impute_and_fill import FillZero, FillAvgWeek\n",
    "\n",
    "previous_week = {\n",
    "    'name': 'PrevWeek',\n",
    "    'model': RollingAverageWeek(1),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillZero()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "previous_week_v2 = {\n",
    "    'name': 'PrevWeek_v2',\n",
    "    'model': RollingAverageWeek(1),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillAvgWeek()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "average_week = {\n",
    "    'name': 'AvgWeek',\n",
    "    'model': RollingAverageWeek(None),\n",
    "    'preprocessing': {\n",
    "        'demand': [],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "rolling_average_2 = {\n",
    "    'name': 'RollingAverage_2',\n",
    "    'model': RollingAverageWeek(2),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillZero()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "rolling_average_4 = {\n",
    "    'name': 'RollingAverage_4',\n",
    "    'model': RollingAverageWeek(4),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillZero()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "rolling_average_8 = {\n",
    "    'name': 'RollingAverage_8',\n",
    "    'model': RollingAverageWeek(8),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillZero()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "auto_rollaw = {\n",
    "    'name': 'AutoRollingAverage',\n",
    "    'model': AutoRollingAverageWeek(),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillAvgWeek()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "\n",
    "models_configs = [\n",
    "    previous_week,\n",
    "    previous_week_v2,\n",
    "    average_week,\n",
    "    rolling_average_2,\n",
    "    rolling_average_4,\n",
    "    rolling_average_8,\n",
    "    auto_rollaw\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp Roll Ave \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.exp_rolling_average_week import ExpWeightedRollingWeek\n",
    "\n",
    "exp_rolling_average_2 = {\n",
    "    'name': 'ExpRollingAverage_2',\n",
    "    'model': ExpWeightedRollingWeek(2),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillAvgWeek()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "exp_rolling_average_4 = {\n",
    "    'name': 'ExpRollingAverage_4',\n",
    "    'model': ExpWeightedRollingWeek(4),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillAvgWeek()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "exp_rolling_average_8 = {\n",
    "    'name': 'ExpRollingAverage_8',\n",
    "    'model': ExpWeightedRollingWeek(8),\n",
    "    'preprocessing': {\n",
    "        'demand': [FillAvgWeek()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "models_configs += [\n",
    "    exp_rolling_average_2,\n",
    "    exp_rolling_average_4,\n",
    "    exp_rolling_average_8\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern regression\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.pattern_regression import PatternRegression, PatternRegressionDaily\n",
    "from preprocessing.simple_transforms import Logarithm\n",
    "from preprocessing.weather_feature_engineering import RealFeel, DewPoint, WindChill\n",
    "\n",
    "pattern_regression = {\n",
    "    'name': f'PatternRegression',\n",
    "    'model': PatternRegression(),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm()],\n",
    "        'weather': [RealFeel(), DewPoint(), WindChill()]\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "pattern_regression_daily = {\n",
    "    'name': f'PatternRegressionDaily',\n",
    "    'model': PatternRegressionDaily(),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm()],\n",
    "        'weather': [RealFeel(), DewPoint(), WindChill()]\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\n",
    "models_configs += [\n",
    "    pattern_regression,\n",
    "    pattern_regression_daily\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prophet\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Support for Torch based models not available. To enable them, install \"darts\", \"u8darts[torch]\" or \"u8darts[all]\" (with pip); or \"u8darts-torch\" or \"u8darts-all\" (with conda).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmodels_configs += [\\n    prophet\\n]\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.fbprophet import Fbprophet\n",
    "\n",
    "prophet = {\n",
    "    'name': 'FbProphet',\n",
    "    'model': Fbprophet(),\n",
    "    'preprocessing': {\n",
    "        'demand': [],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': True\n",
    "}\n",
    "\"\"\"\n",
    "models_configs += [\n",
    "    prophet\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Models \n",
    "### LGBM\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.LGBM import LGBMrobust, LGBMsimple\n",
    "from preprocessing.advanced_transforms import LGBM_demand_features, LGBM_impute_nan_demand\n",
    "from preprocessing.advanced_transforms import LGBM_impute_nan_weather, LGBM_weather_features\n",
    "from preprocessing.advanced_transforms import  LGBM_prepare_test_dfs\n",
    "\n",
    "# No hyperparameter tuning for all parameters\n",
    "lgb_params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'num_leaves': 32,\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.01,\n",
    "        'feature_fraction': 0.6,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq':10,\n",
    "        'verbose': -1\n",
    "}\n",
    "\n",
    "lgbm_simple = {\n",
    "    'name': 'LGBMsimple',\n",
    "    'model': LGBMsimple(lgb_params = lgb_params),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm(), LGBM_impute_nan_demand(), LGBM_demand_features(no_last_week=1)],\n",
    "        'weather': [LGBM_impute_nan_weather(), LGBM_weather_features()],\n",
    "        'prepare_test_dfs': [LGBM_prepare_test_dfs()]\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "lgbm_robust = {\n",
    "    'name': 'LGBMrobust',\n",
    "    'model': LGBMrobust(lgb_params = lgb_params),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm(), LGBM_impute_nan_demand(), LGBM_demand_features(no_last_week=1)],\n",
    "        'weather': [LGBM_impute_nan_weather(), LGBM_weather_features()],\n",
    "        'prepare_test_dfs': [LGBM_prepare_test_dfs()]\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "lgbm_simple_with_last_week = {\n",
    "    'name': 'LGBMsimple_with_last week',\n",
    "    'model': LGBMsimple(lgb_params = lgb_params),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm(), LGBM_impute_nan_demand(), LGBM_demand_features(no_last_week=0)],\n",
    "        'weather': [LGBM_impute_nan_weather(), LGBM_weather_features()],\n",
    "        'prepare_test_dfs': [LGBM_prepare_test_dfs()]\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "\n",
    "models_configs += [\n",
    "    lgbm_simple,\n",
    "    lgbm_robust,\n",
    "    lgbm_simple_with_last_week\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.LGBM import XGBMsimple\n",
    "\n",
    "xgb_params = {\n",
    "    'colsample_bytree': 0.8,\n",
    "    'learning_rate': 0.02,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'objective':'reg:squarederror',\n",
    "    'min_child_weight':10,\n",
    "    'silent':1\n",
    "}\n",
    "\n",
    "xgbm_simple = {\n",
    "    'name': 'XGBMsimple',\n",
    "    'model': XGBMsimple(xgb_params = xgb_params),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm(), LGBM_impute_nan_demand(), LGBM_demand_features(no_last_week=0)],\n",
    "        'weather': [LGBM_impute_nan_weather(), LGBM_weather_features()],\n",
    "        'prepare_test_dfs': [LGBM_prepare_test_dfs()]\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "\n",
    "models_configs += [\n",
    "    xgbm_simple\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSMIX\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.TSMix import TSMix\n",
    "\n",
    "tsmix = {\n",
    "    'name': 'TSMix',\n",
    "    'model': TSMix(train_epochs=50, dropout=0.8),\n",
    "    'preprocessing': {\n",
    "        'demand': [Logarithm(), LGBM_impute_nan_demand()],\n",
    "        'weather': []\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "\n",
    "models_configs += [\n",
    "    tsmix\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavenet\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.wavenet import WaveNetModel, WaveNet_prepare_test_dfs, cfg\n",
    "\n",
    "#cfg['device'] = 'cuda' # if you have a compatible NVIDIA GPU\n",
    "cfg['device'] = 'mps:0' # if you have Metal acceleration on your Mac (https://developer.apple.com/metal/pytorch/)\n",
    "#cfg['device'] = 'cpu' # for every other machine without GPU acceleration\n",
    "\n",
    "wavenet = {\n",
    "    'name': 'WaveNet',\n",
    "    'model': WaveNetModel(cfg),\n",
    "    'preprocessing': {\n",
    "        'demand': [],\n",
    "        'weather': [],\n",
    "        'prepare_test_dfs': [WaveNet_prepare_test_dfs()]\n",
    "    },\n",
    "    'deterministic': False\n",
    "}\n",
    "\n",
    "models_configs += [\n",
    "    wavenet\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we can run the training of all these models and see how they perform\n",
    "wfe.curr_phase='train'\n",
    "wfe.n_train_seeds = 1\n",
    "for config in models_configs:\n",
    "    wfe.add_model(config)\n",
    "\n",
    "# See how they perform with the dashboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After studying the dashboard we selected the models that it made more sense to combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_models_sett = [auto_rollaw,\n",
    "                   pattern_regression,\n",
    "                   lgbm_simple,\n",
    "                   lgbm_robust,\n",
    "                   xgbm_simple,\n",
    "                   lgbm_simple_with_last_week,\n",
    "                   wavenet\n",
    "                   ]\n",
    "wfe.selected_models = [config['name'] for config in selected_models_sett]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase Ensembling study\n",
    "now let's see how the ensembling strategies perfrom on the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's see how the different strategies to reconcile the ensemble work\n",
    "from eval.strategies.best_on_history import BestOnLastNW, BestOnTest\n",
    "\n",
    "strategies = {}\n",
    "strategies['best_on_last'] = BestOnLastNW(1)\n",
    "strategies['best_on_last_2'] = BestOnLastNW(2)\n",
    "strategies['best_on_last_3'] = BestOnLastNW(3)\n",
    "strategies['best_on_test'] = BestOnTest() # like bestonlastNw(4)\n",
    "\n",
    "from eval.strategies.weighted_averages import WeightedAverage\n",
    "import numpy as np\n",
    "\n",
    "top5 = [lgbm_robust, lgbm_simple, xgbm_simple, lgbm_simple_with_last_week, wavenet]\n",
    "\n",
    "strategies['avg_top5'] = WeightedAverage([config['name'] for config in top5], np.ones(len(top5))/len(top5))\n",
    "\n",
    "top3 = [lgbm_robust, lgbm_simple, wavenet]\n",
    "strategies['avg_top3'] = WeightedAverage([config['name'] for config in top3], \n",
    "                                         np.ones(len(top3))/len(top3))\n",
    "\n",
    "strategies['lgbm_wavenet'] = WeightedAverage([lgbm_robust['name'], wavenet['name']], \n",
    "                                             np.array([0.5, 0.5]))\n",
    "\n",
    "# As suggested by Pansos, all the gbm models should count as one model, so 1/3 to rollaverage, 1/3 to gbms 1/3 to wavenet,\n",
    "# and then 1/4 to each of the gbms \n",
    "strategies['gbms_wavenet_arw'] = WeightedAverage([config['name'] for config in selected_models_sett],\n",
    "                                                  np.array([1/3, 0, 1/3/4, 1/3/4, 1/3/4, 1/3/4, 1/3]))\n",
    "\n",
    "# Last strategy is the weighted average where the weights are the ratio between mean and std on the training dataset\n",
    "from Utils.process_results import extract_from\n",
    "from eval.data_loading_helpers import DMAS_NAMES\n",
    "\n",
    "weights = {}\n",
    "for dma in DMAS_NAMES:\n",
    "    dma_pis = [extract_from(wfe.results[model], 1, 'train', 'performance_indicators') for model in wfe.selected_models]\n",
    "    dmas_pi_weight = np.array([(\n",
    "            dma_pis[i].groupby('DMA').mean().loc[dma,'PI3']\n",
    "                                )/(\n",
    "            dma_pis[i].groupby('DMA').std().loc[dma,'PI3']\n",
    "                                ) for i in range(len(dma_pis)) ])\n",
    "    dmas_pi_weight[1] = 0 # I don't want to consider the pattern regression\n",
    "    weights[dma] = dmas_pi_weight/dmas_pi_weight.sum()\n",
    "\n",
    "strategies['wavg_train'] = WeightedAverage([model for model in wfe.selected_models], \n",
    "                                           weights)\n",
    "\n",
    "for strategy in strategies:\n",
    "    wfe.add_strategy(strategy, strategies[strategy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we look at the strategies in thesame dashboard and see how they perform\n",
    "\n",
    "# then we decide which one to go\n",
    "wfe.selected_strategy = 'avg_top5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LGBMsimple with seed 0 in test phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [19:04<00:00, 286.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LGBMsimple with seed 1 in test phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [18:51<00:00, 282.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LGBMsimple with seed 2 in test phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [18:44<00:00, 281.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LGBMrobust with seed 0 in test phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [37:01<00:00, 555.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LGBMrobust with seed 1 in test phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [36:46<00:00, 551.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LGBMrobust with seed 2 in test phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [37:18<00:00, 559.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating XGBMsimple with seed 0 in test phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [18:57<00:00, 284.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating XGBMsimple with seed 1 in test phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [18:47<00:00, 281.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating XGBMsimple with seed 2 in test phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [18:37<00:00, 279.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LGBMsimple_with_last week with seed 0 in test phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [18:54<00:00, 283.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LGBMsimple_with_last week with seed 1 in test phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [18:52<00:00, 283.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LGBMsimple_with_last week with seed 2 in test phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [18:52<00:00, 283.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating WaveNet with seed 0 in test phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300be55b62a2428caf3677a9ed05af99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training for 70 epochs:   0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [12:41<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension specified as -1 but tensor has no dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# run the selected models on the test \u001b[39;00m\n\u001b[1;32m      2\u001b[0m wfe\u001b[38;5;241m.\u001b[39mn_test_seeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mwfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforecast_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/BoN2024/eval/evaluator.py:357\u001b[0m, in \u001b[0;36mWaterFuturesEvaluator.forecast_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurr_phase \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_models:\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfigs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# add model will send the correct database to the eval model function\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m# etract the results of the selected models accordingly\u001b[39;00m\n\u001b[1;32m    360\u001b[0m testresults \u001b[38;5;241m=\u001b[39m extract_results({k: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_models \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults}, \n\u001b[1;32m    361\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurr_it,\n\u001b[1;32m    362\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurr_phase,\n\u001b[1;32m    363\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_weeks\n\u001b[1;32m    364\u001b[0m                             )\n",
      "File \u001b[0;32m~/repos/BoN2024/eval/evaluator.py:161\u001b[0m, in \u001b[0;36mWaterFuturesEvaluator.add_model\u001b[0;34m(self, config, force)\u001b[0m\n\u001b[1;32m    159\u001b[0m l__seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(seed)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with seed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurr_phase\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m phase\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 161\u001b[0m performance_indicators, forecast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweek_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults[config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/repos/BoN2024/eval/evaluator.py:217\u001b[0m, in \u001b[0;36mWaterFuturesEvaluator.eval_model\u001b[0;34m(self, config, test_week_idcs, seed)\u001b[0m\n\u001b[1;32m    214\u001b[0m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mset_seed(seed)\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m \u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdemand_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweather_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# If applicable, prepare test dataframes\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprepare_test_dfs\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessing\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m~/repos/BoN2024/models/wavenet.py:26\u001b[0m, in \u001b[0;36mWaveNetModel.fit\u001b[0;34m(self, demand_train, weather_train)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, demand_train, weather_train):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m WaveNet(cfg)\u001b[38;5;241m.\u001b[39mto(cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdemand_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweather_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/BoN2024/models/wavenet_impl/base_model.py:174\u001b[0m, in \u001b[0;36mBaseModel.fit\u001b[0;34m(self, demand_train, weather_train)\u001b[0m\n\u001b[1;32m    171\u001b[0m     epoch_iterator\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/mae\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;66;03m#if stopper(results['train/mae']):\u001b[39;00m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m#    break\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madjust_bias\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pyenvs/BoN2024_dev_py3116/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/BoN2024/models/wavenet_impl/base_model.py:188\u001b[0m, in \u001b[0;36mBaseModel.adjust_bias\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    186\u001b[0m     pred, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_steps(inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m], inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknown_features\u001b[39m\u001b[38;5;124m'\u001b[39m], steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, residual\u001b[38;5;241m=\u001b[39minputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresidual\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    187\u001b[0m     target_mask \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m--> 188\u001b[0m     \u001b[43mmean_bias\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_bias \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m mean_bias\u001b[38;5;241m.\u001b[39mcompute()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_bias\u001b[38;5;241m.\u001b[39msqueeze())\n",
      "File \u001b[0;32m~/pyenvs/BoN2024_dev_py3116/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pyenvs/BoN2024_dev_py3116/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/pyenvs/BoN2024_dev_py3116/lib/python3.11/site-packages/torchmetrics/wrappers/multioutput.py:145\u001b[0m, in \u001b[0;36mMultioutputWrapper.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39munused\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    140\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call underlying forward methods and aggregate the results if they're non-null.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m    We override this method to ensure that state variables get copied over on the underlying metrics.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m     reshaped_args_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_args_kwargs_by_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    147\u001b[0m         metric(\u001b[38;5;241m*\u001b[39mselected_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mselected_kwargs)\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m metric, (selected_args, selected_kwargs) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics, reshaped_args_kwargs)\n\u001b[1;32m    149\u001b[0m     ]\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m results[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/pyenvs/BoN2024_dev_py3116/lib/python3.11/site-packages/torchmetrics/wrappers/multioutput.py:110\u001b[0m, in \u001b[0;36mMultioutputWrapper._get_args_kwargs_by_output\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m args_kwargs_by_output \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics)):\n\u001b[0;32m--> 110\u001b[0m     selected_args \u001b[38;5;241m=\u001b[39m \u001b[43mapply_to_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     selected_kwargs \u001b[38;5;241m=\u001b[39m apply_to_collection(\n\u001b[1;32m    114\u001b[0m         kwargs, Tensor, torch\u001b[38;5;241m.\u001b[39mindex_select, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim, index\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(i, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    115\u001b[0m     )\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremove_nans:\n",
      "File \u001b[0;32m~/pyenvs/BoN2024_dev_py3116/lib/python3.11/site-packages/lightning_utilities/core/apply_func.py:68\u001b[0m, in \u001b[0;36mapply_to_collection\u001b[0;34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [function(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, dtype) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data):  \u001b[38;5;66;03m# 1d homogeneous tuple\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(function(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mdict\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, dtype) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mvalues()):  \u001b[38;5;66;03m# 1d homogeneous dict\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: function(v, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/pyenvs/BoN2024_dev_py3116/lib/python3.11/site-packages/lightning_utilities/core/apply_func.py:68\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [function(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, dtype) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data):  \u001b[38;5;66;03m# 1d homogeneous tuple\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mdict\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, dtype) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mvalues()):  \u001b[38;5;66;03m# 1d homogeneous dict\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: function(v, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension specified as -1 but tensor has no dimensions"
     ]
    }
   ],
   "source": [
    "# run the selected models on the test \n",
    "wfe.n_test_seeds = 3\n",
    "wfe.forecast_next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qui abbiamo il risultato finale da consegnare per la submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 2\n",
    "We get the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the new data\n",
    "\"\"\"\n",
    "wfe.next_iter()\n",
    "wfe.forecast_next()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BoN2024_dev_py3116",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
